This work has proceeded along two parallel tracks. The first has been gathering primary data through field work as well as using published corpora in the language to uncover grammatical facts. The second is the implementation of the analysis of these grammatical facts through a computational syntactic framework. I will address my methods for each part of this separately.

\subsection{Gathering data in Nuuchahnulth} \label{sec:method:ncn}

Before I began my project on serial verbs and the linker, I first had to learn enough Nuuchahnulth to become at least conversant in the language. I did this by reading the published literature (especially \citealt{sapir1939}), attending language learning classes in Port Alberni (many of them with my colleague, Amie DeJong), and direct study with Adam Werle, some of which was funded through summer Foreign Language Acquisition Scholarships (FLAS). The language lessons I participated in were taught by Adam Werle and often included elders and native speakers who would assist, correct, and aid in teaching. It was through this venue that I first met fluent Nuuchahnulth elders.

In the summer of 2016, Adam and I traveled to Hot Springs Cove and collected texts from some Hesquiaht elders. On request, that data is not presented in this dissertation, but some of that work has informed my analysis, which I have confirmed with other speakers.

\subsubsection{Data sources} \label{sec:method:sources}

I began learning and working with Nuuchahnulth at the start of 2015. Before I collected my own data, I looked at data from a variety of sources to generate appropriate questions. My sources were previous syntactic work on the language, especially \cite{jacobsen1993}, \cite{nakayama2001}, \cite{wojdak2003}, \cite{waldie2004}, and \cite{woo2007b}. I also relied on corpora published by linguists, especially the Nootka Texts \citep{sapir1924, sapir1939, sapir1955, whalingindians2000, whalingindians2004, whalingindians2009}.

In addition to these resources, I looked at community-produced texts such as ``Son of Thunderbird" and texts I received from linguists Adam Werle and Henry Kammler. The largest of these were an in-progress Bible translation Adam Werle and Sophie Billy were working on and several recordings Henry Kammler made with the late Barbara Touchie. I looked through these sources for examples of the phenomena I was looking for, annotated and cataloged them, and used some of these examples as prompts for speakers.

\subsubsection{Elicitation methods} \label{sec:method:elicitation}

I spent January, February, and part of March of 2018 in Port Alberni working with native speakers and gathering data specifically for this dissertation. In that period of time I worked with Julia Lucas (Nuuchahnulth name \textit{tupaat}, Ahousaht tribe, central dialect), Bob Mundy (Uclueleht tribe, Barkley Sound dialect), Marjorie Touchie (Uclueleht tribe, Barkley Sound dialect), Fidelia Haiyupis (Ehattesaht tribe, northern dialect), and Sophie Billy (Checkleseht, Kyuquot-Checkleseht dialect). I also present data I gathered from Simon Lucas (Nuuchahnulth name \textit{yuułnaak}, Heshquiaht tribe, northern dialect), the late husband of Julia Lucas.

I have made an effort to make my work, and at the very least my recordings and transcriptions, available to the communities I have worked with. Some of my work with Fidelia Haiyupis and Sophie Billy was funded by the Ehattesaht tribe, which has received copies of my notes and recordings. The Uclueleht tribal office has also received the notes and recordings I made with Bob Mundy and Marjorie Touchie. I have also made recordings and transcriptions available online to language learners. Some of this information is restricted to people who have the right password to access the folder. I take precautions not to collect data that is sensitive to audience restrictions, and so for most of these materials, password-restricted access is not done out of a concern with rights management, but with the fact that most of these materials are works in progress and I do not want possibly-inaccurate transcriptions to be disseminated widely among people who are lower-level language learners.

When working with speakers, I tended to work two to four hours at a time and tried to structure sections in three parts: grammatical questions and elicitations, vocabulary questions and clarification questions on existing texts, and text elicitation. The purpose of this was to avoid wearing speakers out with too many grammatical questions in a row, and to collect other important data. While there has been good primary linguistic documentation in Nuuchahnulth, particularly in \cite{sapir1939} and \cite{rose1981}, there are many differences across the language's wide spread of dialects that remain undocumented and unknown. Although one of my speakers did not like giving lengthy texts, I was able to collect connected, fluent texts from other speakers, which is a lasting artifact and can be used to answer questions beyond the narrow scope of my dissertation. I have approximately six hours of fluent Nuuchahnulth from that period, about two-thirds of which is currently transcribed. I have since visited my consultants again and asked follow up questions as well as collected more texts.

\subsubsection{Methods of Elicitation}

I used six methods of elicitation, which I will describe below. The aim of all these methods is to obtain the most natural Nuuchahnulth examples or grammatical judgments that are relevant to the phenomenon under investigation. Some methods worked better than others. Only one of my consultants was literate in the language, and while she would correct my pronunciation sometimes by writing out a word, she preferred to work in an oral environment and have me read my notes back to her. That is to say, these elicitation sessions occurred in either a completely or nearly-completely oral context. All Nuuchahnulth speakers I worked with were bilingual in English.

\vspace{8pt}

\noindent \textbf{I. Describing Images}

The aim of this methodology is to avoid the metalanguage (English) through the visual medium. The speaker is presented with a series of images and asked to describe what is going on using only Nuuchahnulth. One set I used was a series of photos of dogs at a reserve. The dogs are hanging out on the pier. They begin barking at the water. A boat approaches the pier. The dogs go up to meet the man in the boat, who pets them. The purpose of this was to elicit a few serial verb constructions, the equivalent of ``The dogs are at the wharf" (locations are verbs in Nuuchahnulth), ``The man drives the boat to the dock" (which would require two verbs). In addition to photo series, I also used hand-drawn pictures on index cards, and existing picture-story books.

I found this method occasionally fruitful but limiting. Sometimes (especially with my hand-drawn cards), speakers would spend a lot of time questioning what the picture was meant to represent. Even with photos, they wanted to know what to focus on: Who is the man in the photo, and who is he related to? While broad grammatical structures could be gathered this way, other methods were more fruitful for eliciting targeted phenomena.

\vspace{8pt}

\noindent \textbf{II. Answering Questions}

Another way of getting natural speech is by asking questions to elicit the phenomenon. In this method, I would tell a short story and ask a question about what happened. Ideally, I hoped elicit a response that uses the grammatical phenomenon in question.

For instance, one of my setups was the following:

\ex \label{ex:wolfsetup}
\begingl
\glpreamble n̓aaciičiƛits hitacsuḥta ʔaƛa saštup. c̓awaak ʕiniiƛ, c̓awaak qʷayac̓iik. ƛawiičiʔats c̓awaakʔi. hitaaqƛ̓iƛ ƛaʔuuʔi. kamitqšiƛit. ʔuḥʔats ʕiniiƛ ƛawiičiʔat. ʔaaqinʔapḥ qʷayac̓iik. //
\gla n̓aac-°iˑčiƛ=(m)it=s hitacsuḥta ʔaƛa saštup. c̓awaak ʕiniiƛ, c̓awaak qʷayac̓iik. ƛaw-°iˑčiƛ=!at=s c̓awaak=ʔiˑ. hitaaqƛ̓iƛ ƛaʔuu=ʔiˑ. kamitq-šiƛ=(m)it. ʔuḥ=!at=s ʕiniiƛ ƛaw-°iˑčiƛ=!at. ʔaaqinʔap=ḥ qʷayac̓iik. //
\glb see-\textsc{in}=\textsc{pst}=\textsc{strg.1sg} out.of.the.forest.\textsc{dr} two animal. one dog, one wolf. near-\textsc{in}=\textsc{pass}=\textsc{strg.sg} dog=\textsc{art}. into.the.forest.\textsc{mo} other=\textsc{art}. run-\textsc{mo}=\textsc{pst}. be=\textsc{pass}=\textsc{strg.1sg} dog approach-\textsc{in}=\textsc{pass}. do.what=\textsc{ques.3} wolf. //
\glft `I saw two creatures come out of the forest. One was a dog, one was a wolf. The dog approached me. The other went back into the forest. He ran. It was the dog that approached me. What did the wolf do?' //
\endgl
\xe

The expected answer is ``The wolf ran into the forest," which requires coordinating the two verbs `run' and `into the forest.' I had very low success rates with this kind of elicitation and quickly abandoned it. Speakers would select the most semantically salient verb, in this case `into the forest', and drop the other verb in the construction. There is probably a better way of using this kind of elicitation method, but I was unable to find how to.

\vspace{8pt}

\noindent \textbf{III. Recording Texts}

My fieldwork also involved recording fluent texts from Nuuchahnulth speakers. This work is a valuable endeavor in itself, but it also allows speakers to give examples of these phenomena in a fluent context. Both linker and serial verb constructions occur naturally in running texts, although not at very high frequencies.

\vspace{8pt}

\noindent \textbf{IV. Rephrasing Stories}

The typical person is interested in language as a means of communication and not a set of abstract grammatical rules. Rephrasing traditional stories or short narratives is one way of trying to get natural versions of grammatical phenomena, especially if the original telling requires those grammatical phenomena. I tried three forms of retelling: (1) asking a speaker to summarize in a few sentences a text I had previously gotten from them; (2) asking a speaker to summarize my own story; (3) asking a speaker to retell a traditional story they may not know well.

I did not have good results with (3), but I did better with (1) and (2). Not every consultant I worked with had the patience to resummarize their own text, but those that did could be persuaded to give a few-sentence quick summary. For retelling my own stories, I quickly found that the best way to do this when I gave a succinct story in English and asked for a retelling in Nuuchahnulth. I typically tried to embed the grammatical illustration at the end. For example, ``I like to walk in the forest in the mornings. There are lots of bluejays in the forest. They must like me, because they follow me around the forest." The first sentence has the opportunity for three verbal expressions in a sentence: location, action, and time. The final sentence also has the possibility for a serial verb construction: a location and an action.

\vspace{8pt}

\noindent \textbf{V. Forced Choice}

Another tool I mixed with rephrasing stories was forced choice. This gives the speaker a few examples to choose from when trying to select the best way to describe something. In my experience, giving speakers a limited set of choices will also lead them to describe what makes one sentence worse, for example ``It could mean something else..." which they would not volunteer without the choice present. If both choices are bad, consultants will also tend to give an explanation why.

One case where I used this was a situation where I am spending time with someone and I am clearly tired. I have a new baby, and I want to explain that the baby kept me up all night. The options were:

\ex \label{becauseofbaby1}
\begingl
\glpreamble ? ʔuusaḥimta nay̓aqakʔi wikitaḥ ƛuł weʔič. //
\gla ʔuusaḥi=imt=maˑ nay̓aqak=ʔiˑ wik=(m)it=(m)aˑḥ ƛuł weʔič //
\glb because.of=\textsc{pst}=\textsc{real.3} baby=\textsc{art} \textsc{neg}=\textsc{pst}=\textsc{real.1sg} good sleep //
\glft ? `I didn't sleep well because of the baby.' //
\endgl
\xe

\ex~ \label{becauseofbaby2}
\begingl
\glpreamble ? ʔuusaḥiqḥita nay̓aqakʔi wikitaḥ ƛuł weʔič. //
\gla ʔuusaḥi-(q)ḥ=(m)it=maˑ nay̓aqak=ʔiˑ wik=(m)it=(m)aˑḥ ƛuł weʔič //
\glb because.of-\textsc{link}=\textsc{pst}=\textsc{real.3} baby=\textsc{art} \textsc{neg}=\textsc{pst}=\textsc{real.1sg} good sleep //
\glft ? `I didn't sleep well because of the baby.' //
\endgl
\xe

In this case, my consultant strongly rejected (\ref{becauseofbaby2}), and this helped me understand how the because words interacted with the linker morpheme. Forced choice was very useful for determining the naturalness of linker constructions, and clear grammatical/ungrammatical judgments.

\vspace{8pt}

\noindent \textbf{VI. Translation}

I also used translation from English, which I consider a less preferable form of elicitation due to the possibility that the speaker will adopt English-like syntactic structures instead of Nuuchahnulth-like structures. However, some speakers were most comfortable with this kind of elicitation task. With one speaker, we worked slowly over a couple of sessions through an abridged translation of The Little Prince.

There were other shorter versions of this kind of elicitation. For instance, ``We are going to go camping. I want the children to help their mother. I want them to pack. I want them to carry the luggage. What should I tell them?" The purpose of this was to get a command form, which is always marked with second position inflection, with a serialized verb construction where the verbs must necessarily share the command mood. The construction would minimally have two (at least pragmatically temporally) sequential verbs and perhaps the benefactive verb to express ``for your mother."

\vspace{8pt}

\noindent \textbf{VII. Grammatical judgments}

A necessary technique was straight grammatical judgments. These were sentences I constructed and asked whether it sounded like something they or someone they knew would say, or if it sounded ``off" in one way or another. I provided context when these came out of the blue. During elicitation sessions, I would also ask if I could rephrase what the speaker said by adding or removing an element, or moving the words around. These in-session rephrases were attempts to get grammatical/ungrammatical examples of the phenomena I was investigating.

\vspace{8pt}

\noindent \textbf{VIII. Constructing a sentence}

There were many instances where I would ask speakers, ``Can you think of a case where you would use this word?" I constructed this method on the fly, as speakers would reject examples I thought were grammatical, or I could not come up with a context that would elicit the construction I was looking for. In most of these cases, I was trying to get an example of a word with a linker morpheme attached (\S\ref{sec:link}).

%My methods of elicitation were: linguist-constructed sentences with preceding context verified or corrected by my consultant, summarization of short stories, finishing an incomplete narrative, requests to rephrase previous speaker utterances, direct translation from English, and description of picture stories. Elicitation was done in Nuuchahnulth when possible, but was often done in English as well. Many of these elicitation methods focused on single actors performing multiple salient actions at once. An example is: ``A wolf and a dog came from the forest. One approached me and one ran back. The dog approached me. What did the wolf do?" The expression `into the forest' in Nuuchahnulth is the verb \textit{hitaaqƛ̓aʔiƛ} and the word for `run' is \textit{kamitquk}. The purpose was to get both in a serial verb construction together. Another example is, ``We are going to go camping. I want the children to help their mother. I want them to pack. I want them to carry the luggage. What should I tell them?" The purpose of this was to get a command form, which is always marked with second position inflection, with a serialized verb construction where the verbs must necessarily share the command mood. The construction would minimally have two (at least pragmatically temporally) sequential verbs and perhaps the benefactive verb to express ``for your mother." Linker constructions were much more difficult to elicit in a roundabout manner like this, and so I often ended up asking directly whether I could attach it to a word, and attempted rephrases of speaker sentences with an added linker morpheme. Sometimes these took the form of ``Is there a way to say this with [word with a linker attached]?"

%I also attempted to elicit stories that would have a greater likelihood of illustrating serial verb or linker phenomenon, which meant settings of simultaneous action. This was not as successful as I had hoped, and I found instead that the best way to gather example constructions was through elicitation methods and gathering as much fluent text as possible. 

None of these methods worked all of the time. Anecdotally, I found that staying in Nuuchahnulth for longer periods of time helped more than anything else, although this was quite difficult to do.

\subsubsection{Data Collation} \label{sec:method:collation}

I collated the examples of the grammatical phenomena I was interested in. These came from a set of stories I had previously interlinearized, from a randomly-selected subset of Nootka Texts stories, from my elicitation sessions with consultants, and from my transcriptions of elicited texts. I entered these examples into a spreadsheet that was tagged with the phenomenon that the example illustrated, and used this to help me find patterns in the grammatical data. To port this data to a test suite that the implemented grammar can run on, I simply had to export it to a comma-separated value file format and run a script that would generate a format readable by the implemented grammar (see \S\ref{sec:method:delphin}).

\subsection{Implementation through the DELPH-IN framework} \label{sec:method:delphin}

My grammatical analysis has been through the DELPH-IN\footnote{\url{http://www.delph-in.net}} framework, which is a computationally-implemented formalism of the head-driven phrase structure grammar (HPSG, \citealt{pollardsag1994}) using Minimal Recursion Semantics (MRS, \citealt{copestake2005}). My implementation is built on a base that uses the Grammar Matrix \citep{bender2002, benderetal2010}.

My first step in the grammar development was to answer a questionnaire on the Grammar Matrix webpage, which generates a baseline grammar in the form of text files in the type description language (TDL). TDL is a series of declarative statements that describe grammatical rules, and the Grammar Matrix is a database of common grammatical rules across the world's languages. For instance, below I replicate a part of the TDL that describes the basic form of a head-complement rule.

\begin{verbatim}
basic-head-comp-phrase := head-valence-phrase & head-compositional &
              binary-headed-phrase &
  [ SYNSEM phr-synsem-min &
           [ LOCAL.CAT [ VAL [ SUBJ #subj,
                               SPEC #spec,
                               SPR #spr ],
                         POSTHEAD #ph,
                         HC-LIGHT #light ],
             LIGHT #light ],
    HEAD-DTR.SYNSEM [ LOCAL.CAT [ VAL [ SUBJ #subj,
                                        SPEC #spec,
                                        SPR #spr ],
                                  HC-LIGHT #light,
                                  POSTHEAD #ph ]],
    NON-HEAD-DTR.SYNSEM canonical-synsem ].
\end{verbatim}

\noindent This rule first states that head-complement rules inherit all the constraints of \texttt{head-valence-phrase}, \texttt{head-compositional}, and \texttt{binary-headed-phrase}. I will gloss over what is present in these rules. Then this rule adds to the constraints of the rules it inherits from, stating that, minus the \textsc{comps} list (where complements are stored), the mother node inherits the valence and \textsc{cat} (category) values of its head-daughter. The non-head-daughter is specified only to be some kind syntactic-semantic item. A further rule, the \texttt{basic-head-1st-comp-phrase}, inherits from the \texttt{basic-head-comp-phrase} and specifies what happens to the head-daughter's complements.

\begin{verbatim}
basic-head-1st-comp-phrase := basic-head-comp-phrase &
  [ SYNSEM.LOCAL.CAT.VAL.COMPS #comps,
    HEAD-DTR.SYNSEM.LOCAL.CAT.VAL.COMPS < #synsem . #comps >,
    NON-HEAD-DTR.SYNSEM #synsem ].
\end{verbatim}

\noindent This rule states that the non-head-daughter is identified with whatever the first thing is on the head-daughter's complements list, and the mother node's complements list is reduced by one. In the case where the head-daughter only has a complements list with one item on it, the value \texttt{\#comps} above will be a null element, and the mother node will have an empty comps list. This means that that node is no longer looking for any complements.

All of the above rule specifications are from the Grammar Matrix, and part of what is drawn on when the system generates an output grammar based on a user's answer to questions. So far the \texttt{basic-head-1st-comp-phrase} says nothing about whether the head or non-head appears first. In my generated grammar, I have a \texttt{head-comp-phrase} that inherits from both the \texttt{basic-head-1st-comp-phrase} above, as well as the \texttt{head-initial} constraint, which simply says that the head is the leftmost element in the structure. Together with a few other constraints, this defines the basic head-complement rule in my Nuuchahnulth grammar.

Once this output from the Grammar Matrix was generated, I could then develop my own, more complex syntactic analyses. This process included generating type hierarchies and lexical entries as well. For instance, below is my definition for a second position clitic lexical item:

[[TODO: Update this]]

\begin{verbatim}
2nd-pos-clitic := lex-item &
  [ SYNSEM [ LOCAL.CAT [ HEAD verb & [ AUX +,
				                       MOD <> ],
             VC -,
             VAL [ SUBJ.FIRST #subj ,
                   COMPS < #comps >,
                   SPR < >,
                   SPEC < > ]]],
    ARG-ST < #comps &
         [ OPT -,
           L-PERIPH +,
           LOCAL [ CAT [ HEAD verb &
                         [ AUX - ],
                         VAL.SUBJ.FIRST #subj ]]] > ].
	
\end{verbatim}

\noindent This rule states that second position clitics are lexical items that are auxiliaries, and have a subject which is equivalent to their complement's subject (the complement being the item they attach to). This rule is my own, and not generated by the Grammar Matrix.

[[TODO: add section about CLIMB? Example TDL??]]

I have limited the scope of my work in two major ways. Firstly, I am not modeling the morphophonology. There are two reasons for this: Morphophonology is theoretically separate from morphosyntax, and the DELPH-IN tool sets are focused entirely on the morphosyntax. Because this is a project modeling multi-predicate constructions, the morphophonology is also not the most relevant component of the grammar. What this means is that a sentence like \textit{ʔuumac̓uk̓ʷaƛaḥ quʔušin} `I am going to talk about Raven' is represented in the grammar in its already-segmented form, ``ʔu-L.mac̓uk =!aƛ=(m)aˑḥ quʔušin."

I am also not separating dialect features into different grammatical models. My data comes from many different dialects of Nuuchahnulth, which each have different morphemes and slightly different grammatical rules. In my grammar's lexicon, I have simply entered all dialect variations. This means that on generation, the grammar is happy to mismatch morphology from different dialects, which is an overgeneration. A larger project would catalog this information by dialect in a larger metagrammar which could then produce separate grammars targeting each dialect. While worthwhile, this project was set aside so I could focus on the multi-predicate constructions.

%In an ideal situation, I would have a grammar for each dialect, generated from a metagrammar that holds information about which grammatical rules and lexical entries belong to each dialect. However, due to time and scope constraints of the project, I simply entered different lexical entries for different dialects into the same grammar. This means that my grammar will happily mismatch morphology from different dialects, which is an incorrect overgeneration. Also due to scope constraints, my grammar also does not include a morphophonological component. This means that the second line of the IGT is what this grammar works with. That is, a sentence like \textit{ʔuumac̓uk̓ʷaƛaḥ quʔušin} `I am going to talk about Raven' is represented in the grammar as ``ʔu-L.mac̓uk =!aƛ=(m)aˑḥ quʔušin." The reasons for this are the theoretical separation of morphophonology from morphosyntax and the focus of the DELPH-IN machinery, which is squarely on morphosyntax and compositional semantics. To generate the surface string from the representation above would require the coding of a morphophonological analyzer (ideally a finite state transducer) which can go from the surface string to the segmented line and vice versa.

Development was done against a test suite of example sentences. These included both grammatical and ungrammatical examples. For the basic components of the grammar, I used simple example sentences from stories or sessions with consultants. Many of the ungrammatical examples for basic clauses were only vetted by me as ungrammatical, but I have a high degree of certainty for their ungrammaticality. For the phenomena under investigation, I used only grammatical examples from my elicitation and corpora work, and ungrammatical examples form my elicitation sessions. These came from my collated data (\S\ref{sec:method:collation}), which was loaded into a \texttt{[incr tsdb()]} database \citep{oepen2001}. This test suite of sentences could be run against each version of the implemented grammar and checked for changes to the parse coverage. Beyond parsing/not-parsing, each example sentence was tested for semantic faithfulness. Semantic validation has to be done manually, but regression tests allowed for parsing results to be compared with previous iterations of the grammar rather than independently reverified every time the grammar changed.

I have focused so far on the parsing component of the grammar. Future work will involve focusing on generation, for which the grammatical tool sets I have used are descriptively adequate. The challenges here involve restricting dialect variation, as mentioned above, as well as restricting certain second position elements which may recurse (an issue explored in more depth in \citealt{bender2010reweaving}). These issues represents avenues for future research and do not affect the validity of the analyses presented here.

%Although the DELPH-IN tool set is descriptive for the purposes of both parsing and generating sentences, I focused only on parsing. My grammar as it stands has some issues with generation. These are caused by insufficient semantic constraints introduced by some morphemes (which can thus be hypothesized endlessly by the generator), and particular difficulties introduced by inflectional second position elements, explored in depth in \cite{bender2010reweaving}. Fixing these issues in generation will require further development of the grammar.

The result of the implemented grammar is a series of files that detail the grammatical rules, the lexicon, and rules for generation. The format for most of these files is TDL, which is a series of grammatical descriptions which are equivalent to HPSG attribute-value matrices. The regression tests in \texttt{[incr tsdb()]} \citep{oepen2001} are also outputted to readable databases which show the resulting coverage of the grammar run over test cases. All of these materials are available at [[TODO: github repo]].

